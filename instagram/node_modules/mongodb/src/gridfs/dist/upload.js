"use strict";
var __extends = (this && this.__extends) || (function () {
    var extendStatics = function (d, b) {
        extendStatics = Object.setPrototypeOf ||
            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||
            function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };
        return extendStatics(d, b);
    };
    return function (d, b) {
        extendStatics(d, b);
        function __() { this.constructor = d; }
        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    };
})();
var __assign = (this && this.__assign) || function () {
    __assign = Object.assign || function(t) {
        for (var s, i = 1, n = arguments.length; i < n; i++) {
            s = arguments[i];
            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))
                t[p] = s[p];
        }
        return t;
    };
    return __assign.apply(this, arguments);
};
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __generator = (this && this.__generator) || function (thisArg, body) {
    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;
    return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() { return this; }), g;
    function verb(n) { return function (v) { return step([n, v]); }; }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while (_) try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [op[0] & 2, t.value];
            switch (op[0]) {
                case 0: case 1: t = op; break;
                case 4: _.label++; return { value: op[1], done: false };
                case 5: _.label++; y = op[1]; op = [0]; continue;
                case 7: op = _.ops.pop(); _.trys.pop(); continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }
                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }
                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }
                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }
                    if (t[2]) _.ops.pop();
                    _.trys.pop(); continue;
            }
            op = body.call(thisArg, _);
        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }
        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };
    }
};
exports.__esModule = true;
exports.GridFSBucketWriteStream = void 0;
var stream_1 = require("stream");
var bson_1 = require("../bson");
var error_1 = require("../error");
var utils_1 = require("../utils");
var write_concern_1 = require("./../write_concern");
/**
 * A writable stream that enables you to write buffers to GridFS.
 *
 * Do not instantiate this class directly. Use `openUploadStream()` instead.
 * @public
 */
var GridFSBucketWriteStream = /** @class */ (function (_super) {
    __extends(GridFSBucketWriteStream, _super);
    /**
     * @param bucket - Handle for this stream's corresponding bucket
     * @param filename - The value of the 'filename' key in the files doc
     * @param options - Optional settings.
     * @internal
     */
    function GridFSBucketWriteStream(bucket, filename, options) {
        var _this = _super.call(this) || this;
        /**
         * The document containing information about the inserted file.
         * This property is defined _after_ the finish event has been emitted.
         * It will remain `null` if an error occurs.
         *
         * @example
         * ```ts
         * fs.createReadStream('file.txt')
         *   .pipe(bucket.openUploadStream('file.txt'))
         *   .on('finish', function () {
         *     console.log(this.gridFSFile)
         *   })
         * ```
         */
        _this.gridFSFile = null;
        options = options !== null && options !== void 0 ? options : {};
        _this.bucket = bucket;
        _this.chunks = bucket.s._chunksCollection;
        _this.filename = filename;
        _this.files = bucket.s._filesCollection;
        _this.options = options;
        _this.writeConcern = write_concern_1.WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;
        // Signals the write is all done
        _this.done = false;
        _this.id = options.id ? options.id : new bson_1.ObjectId();
        // properly inherit the default chunksize from parent
        _this.chunkSizeBytes = options.chunkSizeBytes || _this.bucket.s.options.chunkSizeBytes;
        _this.bufToStore = Buffer.alloc(_this.chunkSizeBytes);
        _this.length = 0;
        _this.n = 0;
        _this.pos = 0;
        _this.state = {
            streamEnd: false,
            outstandingRequests: 0,
            errored: false,
            aborted: false
        };
        if (!_this.bucket.s.calledOpenUploadStream) {
            _this.bucket.s.calledOpenUploadStream = true;
            checkIndexes(_this).then(function () {
                _this.bucket.s.checkedIndexes = true;
                _this.bucket.emit('index');
            }, utils_1.squashError);
        }
        return _this;
    }
    GridFSBucketWriteStream.prototype._construct = function (callback) {
        if (this.bucket.s.checkedIndexes) {
            return process.nextTick(callback);
        }
        this.bucket.once('index', callback);
    };
    GridFSBucketWriteStream.prototype._write = function (chunk, encoding, callback) {
        doWrite(this, chunk, encoding, callback);
    };
    GridFSBucketWriteStream.prototype._final = function (callback) {
        if (this.state.streamEnd) {
            return process.nextTick(callback);
        }
        this.state.streamEnd = true;
        writeRemnant(this, callback);
    };
    /**
     * Places this write stream into an aborted state (all future writes fail)
     * and deletes all chunks that have already been written.
     */
    GridFSBucketWriteStream.prototype.abort = function () {
        return __awaiter(this, void 0, Promise, function () {
            return __generator(this, function (_a) {
                switch (_a.label) {
                    case 0:
                        if (this.state.streamEnd) {
                            // TODO(NODE-3485): Replace with MongoGridFSStreamClosed
                            throw new error_1.MongoAPIError('Cannot abort a stream that has already completed');
                        }
                        if (this.state.aborted) {
                            // TODO(NODE-3485): Replace with MongoGridFSStreamClosed
                            throw new error_1.MongoAPIError('Cannot call abort() on a stream twice');
                        }
                        this.state.aborted = true;
                        return [4 /*yield*/, this.chunks.deleteMany({ files_id: this.id })];
                    case 1:
                        _a.sent();
                        return [2 /*return*/];
                }
            });
        });
    };
    return GridFSBucketWriteStream;
}(stream_1.Writable));
exports.GridFSBucketWriteStream = GridFSBucketWriteStream;
function handleError(stream, error, callback) {
    if (stream.state.errored) {
        process.nextTick(callback);
        return;
    }
    stream.state.errored = true;
    process.nextTick(callback, error);
}
function createChunkDoc(filesId, n, data) {
    return {
        _id: new bson_1.ObjectId(),
        files_id: filesId,
        n: n,
        data: data
    };
}
function checkChunksIndex(stream) {
    return __awaiter(this, void 0, Promise, function () {
        var index, indexes, error_2, hasChunksIndex;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0:
                    index = { files_id: 1, n: 1 };
                    _a.label = 1;
                case 1:
                    _a.trys.push([1, 3, , 4]);
                    return [4 /*yield*/, stream.chunks.listIndexes().toArray()];
                case 2:
                    indexes = _a.sent();
                    return [3 /*break*/, 4];
                case 3:
                    error_2 = _a.sent();
                    if (error_2 instanceof error_1.MongoError && error_2.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {
                        indexes = [];
                    }
                    else {
                        throw error_2;
                    }
                    return [3 /*break*/, 4];
                case 4:
                    hasChunksIndex = !!indexes.find(function (index) {
                        var keys = Object.keys(index.key);
                        if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {
                            return true;
                        }
                        return false;
                    });
                    if (!!hasChunksIndex) return [3 /*break*/, 6];
                    return [4 /*yield*/, stream.chunks.createIndex(index, __assign(__assign({}, stream.writeConcern), { background: true, unique: true }))];
                case 5:
                    _a.sent();
                    _a.label = 6;
                case 6: return [2 /*return*/];
            }
        });
    });
}
function checkDone(stream, callback) {
    if (stream.done) {
        return process.nextTick(callback);
    }
    if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {
        // Set done so we do not trigger duplicate createFilesDoc
        stream.done = true;
        // Create a new files doc
        var gridFSFile_1 = createFilesDoc(stream.id, stream.length, stream.chunkSizeBytes, stream.filename, stream.options.contentType, stream.options.aliases, stream.options.metadata);
        if (isAborted(stream, callback)) {
            return;
        }
        stream.files.insertOne(gridFSFile_1, { writeConcern: stream.writeConcern }).then(function () {
            stream.gridFSFile = gridFSFile_1;
            callback();
        }, function (error) { return handleError(stream, error, callback); });
        return;
    }
    process.nextTick(callback);
}
function checkIndexes(stream) {
    return __awaiter(this, void 0, Promise, function () {
        var doc, index, indexes, error_3, hasFileIndex;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0: return [4 /*yield*/, stream.files.findOne({}, { projection: { _id: 1 } })];
                case 1:
                    doc = _a.sent();
                    if (doc != null) {
                        // If at least one document exists assume the collection has the required index
                        return [2 /*return*/];
                    }
                    index = { filename: 1, uploadDate: 1 };
                    _a.label = 2;
                case 2:
                    _a.trys.push([2, 4, , 5]);
                    return [4 /*yield*/, stream.files.listIndexes().toArray()];
                case 3:
                    indexes = _a.sent();
                    return [3 /*break*/, 5];
                case 4:
                    error_3 = _a.sent();
                    if (error_3 instanceof error_1.MongoError && error_3.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {
                        indexes = [];
                    }
                    else {
                        throw error_3;
                    }
                    return [3 /*break*/, 5];
                case 5:
                    hasFileIndex = !!indexes.find(function (index) {
                        var keys = Object.keys(index.key);
                        if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {
                            return true;
                        }
                        return false;
                    });
                    if (!!hasFileIndex) return [3 /*break*/, 7];
                    return [4 /*yield*/, stream.files.createIndex(index, { background: false })];
                case 6:
                    _a.sent();
                    _a.label = 7;
                case 7: return [4 /*yield*/, checkChunksIndex(stream)];
                case 8:
                    _a.sent();
                    return [2 /*return*/];
            }
        });
    });
}
function createFilesDoc(_id, length, chunkSize, filename, contentType, aliases, metadata) {
    var ret = {
        _id: _id,
        length: length,
        chunkSize: chunkSize,
        uploadDate: new Date(),
        filename: filename
    };
    if (contentType) {
        ret.contentType = contentType;
    }
    if (aliases) {
        ret.aliases = aliases;
    }
    if (metadata) {
        ret.metadata = metadata;
    }
    return ret;
}
function doWrite(stream, chunk, encoding, callback) {
    if (isAborted(stream, callback)) {
        return;
    }
    var inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);
    stream.length += inputBuf.length;
    // Input is small enough to fit in our buffer
    if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {
        inputBuf.copy(stream.bufToStore, stream.pos);
        stream.pos += inputBuf.length;
        process.nextTick(callback);
        return;
    }
    // Otherwise, buffer is too big for current chunk, so we need to flush
    // to MongoDB.
    var inputBufRemaining = inputBuf.length;
    var spaceRemaining = stream.chunkSizeBytes - stream.pos;
    var numToCopy = Math.min(spaceRemaining, inputBuf.length);
    var outstandingRequests = 0;
    while (inputBufRemaining > 0) {
        var inputBufPos = inputBuf.length - inputBufRemaining;
        inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);
        stream.pos += numToCopy;
        spaceRemaining -= numToCopy;
        var doc = void 0;
        if (spaceRemaining === 0) {
            doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));
            ++stream.state.outstandingRequests;
            ++outstandingRequests;
            if (isAborted(stream, callback)) {
                return;
            }
            stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(function () {
                --stream.state.outstandingRequests;
                --outstandingRequests;
                if (!outstandingRequests) {
                    checkDone(stream, callback);
                }
            }, function (error) { return handleError(stream, error, callback); });
            spaceRemaining = stream.chunkSizeBytes;
            stream.pos = 0;
            ++stream.n;
        }
        inputBufRemaining -= numToCopy;
        numToCopy = Math.min(spaceRemaining, inputBufRemaining);
    }
}
function writeRemnant(stream, callback) {
    // Buffer is empty, so don't bother to insert
    if (stream.pos === 0) {
        return checkDone(stream, callback);
    }
    ++stream.state.outstandingRequests;
    // Create a new buffer to make sure the buffer isn't bigger than it needs
    // to be.
    var remnant = Buffer.alloc(stream.pos);
    stream.bufToStore.copy(remnant, 0, 0, stream.pos);
    var doc = createChunkDoc(stream.id, stream.n, remnant);
    // If the stream was aborted, do not write remnant
    if (isAborted(stream, callback)) {
        return;
    }
    stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(function () {
        --stream.state.outstandingRequests;
        checkDone(stream, callback);
    }, function (error) { return handleError(stream, error, callback); });
}
function isAborted(stream, callback) {
    if (stream.state.aborted) {
        process.nextTick(callback, new error_1.MongoAPIError('Stream has been aborted'));
        return true;
    }
    return false;
}
